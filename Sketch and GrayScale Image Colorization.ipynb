{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-10T22:35:17.328979Z","iopub.execute_input":"2023-05-10T22:35:17.329349Z","iopub.status.idle":"2023-05-10T22:35:17.350800Z","shell.execute_reply.started":"2023-05-10T22:35:17.329319Z","shell.execute_reply":"2023-05-10T22:35:17.349919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install fastai","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:35:17.476845Z","iopub.execute_input":"2023-05-10T22:35:17.477119Z","iopub.status.idle":"2023-05-10T22:35:32.145899Z","shell.execute_reply.started":"2023-05-10T22:35:17.477095Z","shell.execute_reply":"2023-05-10T22:35:32.144604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:35:32.148347Z","iopub.execute_input":"2023-05-10T22:35:32.148724Z","iopub.status.idle":"2023-05-10T22:35:32.153921Z","shell.execute_reply.started":"2023-05-10T22:35:32.148689Z","shell.execute_reply":"2023-05-10T22:35:32.152796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import COCO Dataset from FastAI","metadata":{}},{"cell_type":"code","source":"from fastai.data.external import untar_data, URLs\ncoco_path = untar_data(URLs.COCO_SAMPLE)\ncoco_path = str(coco_path) + \"/train_sample\"","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:35:32.155853Z","iopub.execute_input":"2023-05-10T22:35:32.156567Z","iopub.status.idle":"2023-05-10T22:37:03.223451Z","shell.execute_reply.started":"2023-05-10T22:35:32.156537Z","shell.execute_reply":"2023-05-10T22:37:03.222282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports Libraries","metadata":{}},{"cell_type":"code","source":"'''\nfile: dependencies.py\nauthor: @vincit0re\nbrief: This file contains the dependencies for the application.\ndate: 2023-05-05\n'''\n\n# All import statements and libraries\nimport os\nimport glob\nimport time\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2lab, lab2rgb\n\nimport torch\nfrom torch import nn, optim\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, DataLoader\nfrom matplotlib.ticker import MaxNLocator\nimport copy\nuse_gpu = True\ndevice = torch.device(\"cuda\" if (\n    torch.cuda.is_available() and use_gpu) else \"cpu\")\nprint(f\"Using Device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:03.227918Z","iopub.execute_input":"2023-05-10T22:37:03.230042Z","iopub.status.idle":"2023-05-10T22:37:03.936195Z","shell.execute_reply.started":"2023-05-10T22:37:03.230012Z","shell.execute_reply":"2023-05-10T22:37:03.934973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Colorization","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nclass Hyperparameters:\n    '''This contains the hyperparameters for the application.'''\n    _SIZE = 256\n    _DATA_DIR = coco_path\n    _BATCH_SIZE = 32\n    _N_EPOCHS = 50\n    _SAVE_PATH = 'basemodel.pt'","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:03.937721Z","iopub.execute_input":"2023-05-10T22:37:03.938661Z","iopub.status.idle":"2023-05-10T22:37:03.951443Z","shell.execute_reply.started":"2023-05-10T22:37:03.938616Z","shell.execute_reply":"2023-05-10T22:37:03.949179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Images","metadata":{}},{"cell_type":"code","source":"def load_images(path):\n    '''This function loads the images from the path.'''\n    paths = glob.glob(path + \"/*.jpg\") # Grabbing all the image file names\n    np.random.seed(123)\n    paths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 10000 images randomly\n    rand_idxs = np.random.permutation(10_000)\n    train_idxs = rand_idxs[:8000] # choosing the first 8000 as training set\n    val_idxs = rand_idxs[8000:] # choosing last 2000 as validation set\n    train_paths = paths_subset[train_idxs]\n    val_paths = paths_subset[val_idxs]\n    return train_paths, val_paths\n\ntrain_imgs_path, val_imgs_path = load_images(Hyperparameters._DATA_DIR)\n\nprint(f\"Number of Training Images: {len(train_imgs_path)}\")\nprint(f\"Number of Validation Images: {len(val_imgs_path)}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:03.952971Z","iopub.execute_input":"2023-05-10T22:37:03.953439Z","iopub.status.idle":"2023-05-10T22:37:04.230877Z","shell.execute_reply.started":"2023-05-10T22:37:03.953403Z","shell.execute_reply":"2023-05-10T22:37:04.228741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample_images(images_path):\n    images_path = images_path[:16]\n    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n    for ax, img_path in zip(axes.flatten(), images_path):\n        ax.imshow(Image.open(img_path))\n        ax.axis(\"off\")\n\n    plt.suptitle(\"Sample Images\")\n    plt.tight_layout()\n    plt.show()\n\nplot_sample_images(train_imgs_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:04.235230Z","iopub.execute_input":"2023-05-10T22:37:04.235652Z","iopub.status.idle":"2023-05-10T22:37:06.169474Z","shell.execute_reply.started":"2023-05-10T22:37:04.235611Z","shell.execute_reply":"2023-05-10T22:37:06.168304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Class","metadata":{}},{"cell_type":"code","source":"# dataset class\nclass ColorizationDataset(Dataset):\n    def __init__(self, paths, split='train', size=256):\n        self.SIZE = size\n        if split == 'train':\n            self.transforms = transforms.Compose([\n                transforms.Resize((self.SIZE, self.SIZE),  Image.BICUBIC),\n                transforms.RandomHorizontalFlip(),  # A little data augmentation!\n            ])\n        elif split == 'val':\n            self.transforms = transforms.Resize(\n                (self.SIZE, self.SIZE),  Image.BICUBIC)\n\n        self.split = split\n        self.size = self.SIZE\n        self.paths = paths\n\n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        img = self.transforms(img)\n        img = np.array(img)\n        img_lab = rgb2lab(img).astype(\"float32\")  # Converting RGB to L*a*b\n        img_lab = transforms.ToTensor()(img_lab)\n        L = img_lab[[0], ...] / 50. - 1.  # Between -1 and 1\n        ab = img_lab[[1, 2], ...] / 110.  # Between -1 and 1\n\n        return {'L': L, 'ab': ab}\n\n    def __len__(self):\n        return len(self.paths)\n\n\n# A handy function to make our dataloaders\ndef make_dataloaders(batch_size=16, n_workers=2, pin_memory=True, **kwargs):\n    dataset = ColorizationDataset(size= Hyperparameters._SIZE, **kwargs)\n    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n                            pin_memory=pin_memory)\n    return dataloader\n\n# get train, val dataloaders\n\n\ndef get_train_val_dataloaders(train_paths, val_paths, batch_size=64, shuffle=True):\n    '''This function returns the train, validation and test dataloaders.'''\n    train_dataloader = make_dataloaders(\n        batch_size=batch_size, paths=train_paths, split='train')\n    val_dataloader = make_dataloaders(\n        \n        batch_size=batch_size, paths=val_paths, split='val')\n    return train_dataloader, val_dataloader\n\ntrain_loader, val_loader = get_train_val_dataloaders(train_paths=train_imgs_path, val_paths=val_imgs_path, batch_size=Hyperparameters._BATCH_SIZE, shuffle=True)\nprint(f\"Train Data: {len(train_loader.dataset)} ({len(train_loader)} batches)\")\nprint(f\"Validation Data: {len(val_loader.dataset)} ({len(val_loader)} batches)\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:06.170805Z","iopub.execute_input":"2023-05-10T22:37:06.171173Z","iopub.status.idle":"2023-05-10T22:37:06.198404Z","shell.execute_reply.started":"2023-05-10T22:37:06.171138Z","shell.execute_reply":"2023-05-10T22:37:06.194185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in train_loader:\n    print(batch['L'].shape)\n    print(batch['ab'].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:06.200671Z","iopub.execute_input":"2023-05-10T22:37:06.201083Z","iopub.status.idle":"2023-05-10T22:37:12.225952Z","shell.execute_reply.started":"2023-05-10T22:37:06.201048Z","shell.execute_reply":"2023-05-10T22:37:12.224756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## U-Net","metadata":{}},{"cell_type":"code","source":"# block for UNet\n\n\nclass UnetBlock(nn.Module):\n    '''This is the block for the UNet.\n        Args:\n            nf (int): Number of filters.\n            ni (int): Number of input channels.\n            submodule (nn.Module): Submodule.\n            input_c (int): Number of input channels.\n            dropout (bool): Dropout.\n            innermost (bool): Innermost.\n            outermost (bool): Outermost.\n    '''\n\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None:\n            input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf)\n\n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout:\n                up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n\n    # forward\n    def forward(self, x):\n#         print(x.shape)\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n        \n# class for UNet\n\n\nclass Unet(nn.Module):\n    '''This is the UNet class.\n        Args:\n            input_c (int): Number of input channels.\n            output_c (int): Number of output channels.\n            n_down (int): Number of down samples.\n            num_filters (int): Number of filters.\n    '''\n\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n        super().__init__()\n        unet_block = UnetBlock(\n            num_filters * 8, num_filters * 8, innermost=True)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(\n                num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(\n                out_filters // 2, out_filters, submodule=unet_block)\n            out_filters //= 2\n        self.model = UnetBlock(\n            output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:12.232321Z","iopub.execute_input":"2023-05-10T22:37:12.233105Z","iopub.status.idle":"2023-05-10T22:37:12.251427Z","shell.execute_reply.started":"2023-05-10T22:37:12.233055Z","shell.execute_reply":"2023-05-10T22:37:12.250560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Unet())","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:12.252605Z","iopub.execute_input":"2023-05-10T22:37:12.253007Z","iopub.status.idle":"2023-05-10T22:37:12.848784Z","shell.execute_reply.started":"2023-05-10T22:37:12.252970Z","shell.execute_reply":"2023-05-10T22:37:12.847771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Discriminator","metadata":{}},{"cell_type":"code","source":"# discriminator class\n\n\nclass PatchDiscriminator(nn.Module):\n    '''This is the discriminator class.\n        Args:\n            input_c (int): Number of input channels.\n            num_filters (int): Number of filters.\n            n_down (int): Number of down samples.\n    '''\n\n    def __init__(self, input_c, num_filters=64, n_down=3):\n        super().__init__()\n        model = [self.get_layers(input_c, num_filters, norm=False)]\n        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n                  for i in range(n_down)]  # the 'if' statement is taking care of not using\n        # stride of 2 for the last block in this loop\n        # Make sure to not use normalization or\n        model += [self.get_layers(num_filters * 2 **\n                                  n_down, 1, s=1, norm=False, act=False)]\n        # activation for the last layer of the model\n        self.model = nn.Sequential(*model)\n\n    # when needing to make some repetitive blocks of layers,\n    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n        # it's always helpful to make a separate method for that purpose\n        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]\n        if norm:\n            layers += [nn.BatchNorm2d(nf)]\n        if act:\n            layers += [nn.LeakyReLU(0.2, True)]\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:12.850068Z","iopub.execute_input":"2023-05-10T22:37:12.850997Z","iopub.status.idle":"2023-05-10T22:37:12.861631Z","shell.execute_reply.started":"2023-05-10T22:37:12.850962Z","shell.execute_reply":"2023-05-10T22:37:12.860480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(PatchDiscriminator(input_c=1))","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:12.864898Z","iopub.execute_input":"2023-05-10T22:37:12.865635Z","iopub.status.idle":"2023-05-10T22:37:12.900867Z","shell.execute_reply.started":"2023-05-10T22:37:12.865603Z","shell.execute_reply":"2023-05-10T22:37:12.899908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GAN Loss","metadata":{}},{"cell_type":"code","source":"# gan loss\n\n\nclass GANLoss(nn.Module):\n    '''This is the GAN loss.\n        Args:\n            gan_mode (str): GAN mode.\n            real_label (float): Real label.\n            fake_label (float): Fake label.\n    '''\n\n    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n        super().__init__()\n        self.register_buffer('real_label', torch.tensor(real_label))\n        self.register_buffer('fake_label', torch.tensor(fake_label))\n        if gan_mode == 'vanilla':\n            self.loss = nn.BCEWithLogitsLoss()\n        elif gan_mode == 'lsgan':\n            self.loss = nn.MSELoss()\n\n    def get_labels(self, preds, target_is_real):\n        if target_is_real:\n            labels = self.real_label\n        else:\n            labels = self.fake_label\n        return labels.expand_as(preds)\n\n    def __call__(self, preds, target_is_real):\n        labels = self.get_labels(preds, target_is_real)\n        loss = self.loss(preds, labels)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:12.902382Z","iopub.execute_input":"2023-05-10T22:37:12.902717Z","iopub.status.idle":"2023-05-10T22:37:12.911182Z","shell.execute_reply.started":"2023-05-10T22:37:12.902687Z","shell.execute_reply":"2023-05-10T22:37:12.909938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Initialization","metadata":{}},{"cell_type":"code","source":"# weights initialization\n\n\ndef init_weights(net, init='norm', gain=0.02):\n\n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and 'Conv' in classname:\n            if init == 'norm':\n                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n            elif init == 'xavier':\n                nn.init.xavier_normal_(m.weight.data, gain=gain)\n            elif init == 'kaiming':\n                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n\n            if hasattr(m, 'bias') and m.bias is not None:\n                nn.init.constant_(m.bias.data, 0.0)\n        elif 'BatchNorm2d' in classname:\n            nn.init.normal_(m.weight.data, 1., gain)\n            nn.init.constant_(m.bias.data, 0.)\n\n    net.apply(init_func)\n    print(f\"model initialized with {init} initialization\")\n    return net\n\n# model initialization\n\n\ndef init_model(model, device):\n    model = model.to(device)\n    model = init_weights(model)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:12.912741Z","iopub.execute_input":"2023-05-10T22:37:12.913134Z","iopub.status.idle":"2023-05-10T22:37:12.925897Z","shell.execute_reply.started":"2023-05-10T22:37:12.913099Z","shell.execute_reply":"2023-05-10T22:37:12.924861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Model","metadata":{}},{"cell_type":"code","source":"# main model\n\n\nclass MainModel(nn.Module):\n    '''This is the main model class.\n        Args:\n            net_G (nn.Module): Generator network.\n            lr_G (float): Learning rate for the generator.\n            lr_D (float): Learning rate for the discriminator.\n            beta1 (float): Beta1 for Adam optimizer.\n            beta2 (float): Beta2 for Adam optimizer.\n            lambda_L1 (float): Weight for L1 loss.\n    '''\n\n    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n        super().__init__()\n\n        self.device = torch.device(\n            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.lambda_L1 = lambda_L1\n\n        if net_G is None:\n            self.net_G = init_model(\n                Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n        else:\n            self.net_G = net_G.to(self.device)\n        self.net_D = init_model(PatchDiscriminator(\n            input_c=3, n_down=3, num_filters=64), self.device)\n        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n        self.L1criterion = nn.L1Loss()\n        self.opt_G = optim.Adam(self.net_G.parameters(),\n                                lr=lr_G, betas=(beta1, beta2))\n        self.opt_D = optim.Adam(self.net_D.parameters(),\n                                lr=lr_D, betas=(beta1, beta2))\n\n    def set_requires_grad(self, model, requires_grad=True):\n        for p in model.parameters():\n            p.requires_grad = requires_grad\n\n    def setup_input(self, data):\n        self.L = data['L'].to(self.device)\n        self.ab = data['ab'].to(self.device)\n\n    def forward(self):\n        self.fake_color = self.net_G(self.L)\n\n    def backward_D(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image.detach())\n        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n        real_image = torch.cat([self.L, self.ab], dim=1)\n        real_preds = self.net_D(real_image)\n        self.loss_D_real = self.GANcriterion(real_preds, True)\n        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n        self.loss_D.backward()\n\n    def backward_G(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image)\n        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n        self.loss_G_L1 = self.L1criterion(\n            self.fake_color, self.ab) * self.lambda_L1\n        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n        self.loss_G.backward()\n\n    def optimize(self):\n        self.forward()\n        self.net_D.train()\n        self.set_requires_grad(self.net_D, True)\n        self.opt_D.zero_grad()\n        self.backward_D()\n        self.opt_D.step()\n\n        self.net_G.train()\n        self.set_requires_grad(self.net_D, False)\n        self.opt_G.zero_grad()\n        self.backward_G()\n        self.opt_G.step()","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:12.927318Z","iopub.execute_input":"2023-05-10T22:37:12.927910Z","iopub.status.idle":"2023-05-10T22:37:12.947782Z","shell.execute_reply.started":"2023-05-10T22:37:12.927874Z","shell.execute_reply":"2023-05-10T22:37:12.946892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"# average meter class for loss\n\n\nclass AverageMeter:\n    '''This class is used to keep track of loss and other metrics.'''\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.count, self.avg, self.sum = [0.] * 3\n\n    def update(self, val, count=1):\n        self.count += count\n        self.sum += count * val\n        self.avg = self.sum / self.count\n\n# create loss meters\n\n\ndef create_loss_meters():\n    loss_D_fake = AverageMeter()\n    loss_D_real = AverageMeter()\n    loss_D = AverageMeter()\n    loss_G_GAN = AverageMeter()\n    loss_G_L1 = AverageMeter()\n    loss_G = AverageMeter()\n\n    return {'loss_D_fake': loss_D_fake,\n            'loss_D_real': loss_D_real,\n            'loss_D': loss_D,\n            'loss_G_GAN': loss_G_GAN,\n            'loss_G_L1': loss_G_L1,\n            'loss_G': loss_G}\n\n# update loss meters in training\n\n\ndef update_losses(model, loss_meter_dict, count):\n    for loss_name, loss_meter in loss_meter_dict.items():\n        loss = getattr(model, loss_name)\n        loss_meter.update(loss.item(), count=count)\n\n# plot losses\n\n\ndef lab_to_rgb(L, ab):\n    \"\"\"\n    Takes a batch of images\n    \"\"\"\n\n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n    rgb_imgs = []\n    for img in Lab:\n        img_rgb = lab2rgb(img)\n        rgb_imgs.append(img_rgb)\n    return np.stack(rgb_imgs, axis=0)\n\n# visualize results\n\n\ndef visualize(model, data, save=True):\n    model.net_G.eval()\n    with torch.no_grad():\n        model.setup_input(data)\n        model.forward()\n    model.net_G.train()\n    fake_color = model.fake_color.detach()\n    real_color = model.ab\n    L = model.L\n    fake_imgs = lab_to_rgb(L, fake_color)\n    real_imgs = lab_to_rgb(L, real_color)\n    fig = plt.figure(figsize=(15, 8))\n    for i in range(5):\n        ax = plt.subplot(3, 5, i + 1)\n        ax.imshow(L[i][0].cpu(), cmap='gray')\n        ax.axis(\"off\")\n        ax = plt.subplot(3, 5, i + 1 + 5)\n        ax.imshow(fake_imgs[i])\n        ax.axis(\"off\")\n        ax = plt.subplot(3, 5, i + 1 + 10)\n        ax.imshow(real_imgs[i])\n        ax.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n    if not os.path.exists(\"results\"):\n        os.makedirs(\"results\")\n    if save:\n        fig.savefig(f\"results/colorization_{time.time()}.png\")\n\n# print results\n\n\ndef log_results(loss_meter_dict):\n    for loss_name, loss_meter in loss_meter_dict.items():\n        print(f\"{loss_name}: {loss_meter.avg:.5f}\")\n        if not os.path.exists('losses.txt'):\n            with open('losses.txt', 'w') as f:\n                f.write(f\"{loss_name}: {loss_meter.avg:.5f}\\n\")\n        else:\n            with open('losses.txt', 'a') as f:\n                f.write(f\"{loss_name}: {loss_meter.avg:.5f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:37:12.949010Z","iopub.execute_input":"2023-05-10T22:37:12.949835Z","iopub.status.idle":"2023-05-10T22:37:12.969342Z","shell.execute_reply.started":"2023-05-10T22:37:12.949801Z","shell.execute_reply":"2023-05-10T22:37:12.968311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_dl, val_dl, epochs, display_every=200, save_path='model.pt'):\n    best_loss = 1e10\n    best_model = None\n    \n    for e in range(epochs):\n        # getting a batch for visualizing the model output after fixed intervals\n        data_val = next(iter(val_dl))\n        # function returning a dictionary of objects to\n        loss_meter_dict = create_loss_meters()\n        i = 0                                  # log the losses of the complete network\n        for data in tqdm(train_dl):\n            model.setup_input(data)\n            model.optimize()\n            # function updating the log objects\n            update_losses(model, loss_meter_dict, count=data['L'].size(0))\n            i += 1\n            if i % display_every == 0:\n                print(f\"\\nEpoch {e+1}/{epochs}\")\n                print(f\"Iteration {i}/{len(train_dl)}\")\n                # function to print out the losses\n                log_results(loss_meter_dict)\n                # function displaying the model's outputs\n                visualize(model, data_val, save=True)        \n        \n        # save model after every epoch\n        if loss_meter_dict['loss_G'].avg < best_loss:\n            best_loss = loss_meter_dict['loss_G'].avg\n            best_model = model\n\n    torch.save(best_model, save_path)\n    return best_model","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:50:54.375379Z","iopub.execute_input":"2023-05-10T22:50:54.375766Z","iopub.status.idle":"2023-05-10T22:50:54.387436Z","shell.execute_reply.started":"2023-05-10T22:50:54.375727Z","shell.execute_reply":"2023-05-10T22:50:54.386213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training ","metadata":{}},{"cell_type":"code","source":"model = MainModel()\ntrained_model = train_model(model, train_loader, val_loader, epochs= Hyperparameters._N_EPOCHS, save_path= Hyperparameters._SAVE_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:50:59.703123Z","iopub.execute_input":"2023-05-10T22:50:59.703884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get losses from results.txt\n\n\ndef get_losses(results_path):\n    with open(results_path, 'r') as f:\n        lines = f.readlines()\n\n    # loss_D_fake: 0.44797\n    # loss_D_real: 0.48049\n    # loss_D: 0.46423\n    # loss_G_GAN: 1.60854\n    # loss_G_L1: 9.48314\n    # loss_G: 11.09168\n\n    losses_D_fake = []\n    losses_D_real = []\n    losses_D = []\n    losses_G_GAN = []\n    losses_G_L1 = []\n    losses_G = []\n\n    for line in lines:\n        if \"loss_D_fake\" in line:\n            losses_D_fake.append(float(line.split(\":\")[1]))\n        elif \"loss_D_real\" in line:\n            losses_D_real.append(float(line.split(\":\")[1]))\n        elif \"loss_D\" in line:\n            losses_D.append(float(line.split(\":\")[1]))\n        elif \"loss_G_GAN\" in line:\n            losses_G_GAN.append(float(line.split(\":\")[1]))\n        elif \"loss_G_L1\" in line:\n            losses_G_L1.append(float(line.split(\":\")[1]))\n        elif \"loss_G\" in line:\n            losses_G.append(float(line.split(\":\")[1]))\n\n    return losses_D_fake, losses_D_real, losses_D, losses_G_GAN, losses_G_L1, losses_G\n\n# plot loss curves\n\n\ndef plot_losses(losses, save_path=None):\n    labels = [\"loss_D_fake\", \"loss_D_real\", \"loss_D\",\n              \"loss_G_GAN\", \"loss_G_L1\", \"loss_G\"]\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n    ax[0].plot(losses[0], \"*-\", label=labels[0])\n    ax[0].plot(losses[1], \"*-\", label=labels[1])\n    ax[0].plot(losses[2], \"*-\", label=labels[2])\n    ax[0].set_xlabel(\"Iterations\")\n    ax[0].set_ylabel(\"Loss\")\n    ax[0].xaxis.set_major_locator(MaxNLocator(integer=True))\n    ax[0].legend()\n    ax[0].set_title(\"Discriminator Losses\")\n\n    ax[1].plot(losses[3], \"*-\", label=labels[3])\n    ax[1].plot(losses[4], \"*-\", label=labels[4])\n    ax[1].plot(losses[5], \"*-\", label=labels[5])\n    ax[1].set_xlabel(\"Iterations\")\n    ax[1].set_ylabel(\"Loss\")\n    ax[1].xaxis.set_major_locator(MaxNLocator(integer=True))\n    ax[1].legend()\n    ax[1].set_title(\"Generator Losses\")\n    plt.suptitle(\"Loss Curves\")\n    plt.tight_layout()\n    plt.show()\n    if save_path:\n        fig.savefig(save_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:49:04.030733Z","iopub.execute_input":"2023-05-10T22:49:04.031135Z","iopub.status.idle":"2023-05-10T22:49:04.052814Z","shell.execute_reply.started":"2023-05-10T22:49:04.031094Z","shell.execute_reply":"2023-05-10T22:49:04.051565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses = get_losses(\"losses.txt\")\nplot_losses(losses, save_path=\"losses.png\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:49:04.054496Z","iopub.execute_input":"2023-05-10T22:49:04.055269Z","iopub.status.idle":"2023-05-10T22:49:04.851622Z","shell.execute_reply.started":"2023-05-10T22:49:04.055205Z","shell.execute_reply":"2023-05-10T22:49:04.850516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"def predict_on_test_data(test_loader, model_path):\n    '''This function returns the colorized version of the images in the test set.\n        Args:\n            test_loader (torch.utils.data.DataLoader): Test data loader.\n            model_path (str): Path to the model.\n        Returns:\n            colorized_imgs (list): List of colorized images.\n    '''\n    count = 0\n    model = torch.load(model_path)\n    for data in test_loader:\n        visualize(model=model, data=data, save=True)\n        count += 1\n        if count >= 2:\n            break","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:49:04.853224Z","iopub.execute_input":"2023-05-10T22:49:04.853662Z","iopub.status.idle":"2023-05-10T22:49:04.860387Z","shell.execute_reply.started":"2023-05-10T22:49:04.853624Z","shell.execute_reply":"2023-05-10T22:49:04.859371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_on_test_data(val_loader, '/kaggle/working/basemodel.pt')","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:49:04.861910Z","iopub.execute_input":"2023-05-10T22:49:04.863016Z","iopub.status.idle":"2023-05-10T22:49:15.634390Z","shell.execute_reply.started":"2023-05-10T22:49:04.862941Z","shell.execute_reply":"2023-05-10T22:49:15.633158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GrayScale Images","metadata":{}},{"cell_type":"code","source":"# get colored image from a given image\n\n\ndef get_colorized_image(img_path, model_path, SIZE=256, save_path=None):\n    '''This function returns the colorized version of a given image.\n        Args:\n            img_path (str): Path to the image.\n            model_path (str): Path to the model.\n        Returns:\n            colorized_img (numpy.ndarray): Colorized version of the image.\n    '''\n    transform = transforms.Resize(\n        (SIZE, SIZE),  Image.BICUBIC)\n\n    img = Image.open(img_path).convert(\"RGB\")\n    img = transform(img)\n    img = np.array(img)\n    img_lab = rgb2lab(img).astype(\"float32\")  # Converting RGB to L*a*b\n    img_lab = transforms.ToTensor()(img_lab)\n    L = img_lab[[0], ...] / 50. - 1.  # Between -1 and 1\n    ab = img_lab[[1, 2], ...] / 110.  # Between -1 and 1\n\n    data = {\"L\": L.unsqueeze(0), \"ab\": ab.unsqueeze(0)}\n    model = torch.load(model_path)\n    model.net_G.eval()\n    with torch.no_grad():\n        model.setup_input(data)\n        model.forward()\n    model.net_G.train()\n    fake_color = model.fake_color.detach()\n    real_color = model.ab\n    L = model.L\n    fake_imgs = lab_to_rgb(L, fake_color)\n    real_imgs = lab_to_rgb(L, real_color)\n\n    return fake_imgs[0], real_imgs[0]\n\n# show the image\n\n\ndef plot_comparison(fake_img, real_img, save_path=None):\n\n    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n    ax[0].imshow(fake_img)\n    ax[0].set_title(\"Colored\")\n    ax[1].imshow(real_img)\n    ax[1].set_title(\"Original\")\n    ax[0].axis(\"off\")\n    ax[1].axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n    if save_path is not None:\n        plt.savefig(save_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:49:15.637428Z","iopub.execute_input":"2023-05-10T22:49:15.638274Z","iopub.status.idle":"2023-05-10T22:49:15.656082Z","shell.execute_reply.started":"2023-05-10T22:49:15.638216Z","shell.execute_reply":"2023-05-10T22:49:15.655044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results on Grayscale Images","metadata":{}},{"cell_type":"code","source":"img_dir = '/kaggle/input/grayscale-imgs/grayscale'\nmodel_path = '/kaggle/working/basemodel.pt'\nif not os.path.exists(\"outputs\"):\n        os.makedirs(\"outputs\")\nfor img in os.listdir(img_dir):\n    img_path = os.path.join(img_dir, img)\n    col_img, real_img = get_colorized_image(\n        img_path, model_path)\n    plot_comparison(col_img, real_img, save_path=\"outputs/\"+img)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T22:49:15.657416Z","iopub.execute_input":"2023-05-10T22:49:15.658257Z","iopub.status.idle":"2023-05-10T22:49:31.326296Z","shell.execute_reply.started":"2023-05-10T22:49:15.658201Z","shell.execute_reply":"2023-05-10T22:49:31.325054Z"},"trusted":true},"execution_count":null,"outputs":[]}]}